{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ID20178\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Original data\n",
    "train = pd.read_csv('power-laws-forecasting-energy-consumption-training-data.csv', sep=';', index_col=0)\n",
    "test = pd.read_csv('power-laws-forecasting-energy-consumption-submission-format.csv', sep=';', index_col=0)\n",
    "\n",
    "weather = pd.read_csv('power-laws-forecasting-energy-consumption-weather.csv', sep=';')\n",
    "meta = pd.read_csv('power-laws-forecasting-energy-consumption-metadata.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrac features and convert the time into cyclical variables\n",
    "def process_time(df):\n",
    "    \n",
    "    # Convert timestamp into a pandas datatime object\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df = df.set_index('Timestamp')\n",
    "    \n",
    "    # Extract units of time from the timestamp\n",
    "    df['min'] = df.index.minute\n",
    "    df['hour'] = df.index.hour\n",
    "    df['wday'] = df.index.dayofweek\n",
    "    df['mday'] = df.index.day\n",
    "    df['yday'] = df.index.dayofyear\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    \n",
    "    # Create a time of day to represent hours and minutes\n",
    "    df['time'] = df['hour'] + (df['min'] / 60)\n",
    "    df = df.drop(columns=['hour', 'min'])\n",
    "    \n",
    "    # Cyclical variable transformations\n",
    "    \n",
    "    # wday has period of 6\n",
    "    df['wday_sin'] = np.sin(2 * np.pi * df['wday'] / 6)\n",
    "    df['wday_cos'] = np.cos(2 * np.pi * df['wday'] / 6)\n",
    "    \n",
    "    # yday has period of 365\n",
    "    df['yday_sin'] = np.sin(2 * np.pi * df['yday'] / 365)\n",
    "    df['yday_cos'] = np.cos(2 * np.pi * df['yday'] / 365)\n",
    "    \n",
    "    # month has period of 12\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    # time has period of 24\n",
    "    df['time_sin'] = np.sin(2 * np.pi * df['time'] / 24)\n",
    "    df['time_cos'] = np.cos(2 * np.pi * df['time'] / 24)\n",
    "    \n",
    "    # turn the index into a column\n",
    "    df = df.reset_index(level=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering of the time for train and test\n",
    "train = process_time(train)\n",
    "test = process_time(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add weather information into a dataset\n",
    "def add_weather(df, weather):\n",
    "    \n",
    "    # Keep track of the original length of the dataset\n",
    "    original_length = len(df)\n",
    "    \n",
    "    # Convert timestamp to a pandas datetime object\n",
    "    weather['Timestamp'] = pd.to_datetime(weather['Timestamp'])\n",
    "    weather = weather.set_index('Timestamp')\n",
    "    \n",
    "    # Round the  weather data to the nearest 15 minutes\n",
    "    weather.index = weather.index.round(freq='15 min')\n",
    "    weather = weather.reset_index(level=0)\n",
    "    \n",
    "    # Merge the building data with the weather data\n",
    "    df = pd.merge(df, weather, how = 'left', on = ['Timestamp', 'SiteId'])\n",
    "    \n",
    "    # Drop the duplicate temperature measurements, keeping the closest location\n",
    "    df = df.sort_values(['Timestamp', 'SiteId', 'Distance'])\n",
    "    df = df.drop_duplicates(['Timestamp', 'SiteId'], keep='first')\n",
    "    \n",
    "    # Checking length of new data\n",
    "    new_length = len(df)\n",
    "    \n",
    "    # Check to make sure the length of the dataset has not changed\n",
    "    assert original_length == new_length, 'New Length must match original length'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weather information for both train and test data\n",
    "train = add_weather(train, weather)\n",
    "test = add_weather(test, weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ids and new dataframe to hold meta information\n",
    "id_list = set(meta['SiteId'])\n",
    "all_meta = pd.DataFrame(columns=['SiteId', 'wday', 'off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each site and find days off\n",
    "for site in id_list:\n",
    "    # Extract the metadata information for the site\n",
    "    meta_slice = meta[meta['SiteId'] == site]\n",
    "    \n",
    "    # Create a new dataframe for the site\n",
    "    site_meta = pd.DataFrame(columns=['SiteId', 'wday', 'off'],\n",
    "                            index = [0, 1, 2, 3, 4, 5, 6])\n",
    "    \n",
    "    site_meta['wday'] = [0, 1, 2, 3, 4, 5, 6]\n",
    "    site_meta['SiteId'] = site\n",
    "    \n",
    "    # Record the days off\n",
    "    site_meta.loc[0, 'off'] = float(meta_slice['MondayIsDayOff'])\n",
    "    site_meta.loc[1, 'off'] = float(meta_slice['TuesdayIsDayOff'])\n",
    "    site_meta.loc[2, 'off'] = float(meta_slice['WednesdayIsDayOff'])\n",
    "    site_meta.loc[3, 'off'] = float(meta_slice['ThursdayIsDayOff'])\n",
    "    site_meta.loc[4, 'off'] = float(meta_slice['FridayIsDayOff'])\n",
    "    site_meta.loc[5, 'off'] = float(meta_slice['SaturdayIsDayOff'])\n",
    "    site_meta.loc[6, 'off'] = float(meta_slice['SundayIsDayOff'])\n",
    "    \n",
    "    # Append the resulting dataframe to all site dataframe\n",
    "    all_meta = all_meta.append(site_meta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the days off in the training and testing data\n",
    "train = train.merge(all_meta, how = 'left', on = ['SiteId', 'wday'])\n",
    "test = test.merge(all_meta, how = 'left', on = ['SiteId', 'wday'])\n",
    "\n",
    "# Save files to csv\n",
    "train.to_csv('train_corrected.csv', index = False)\n",
    "test.to_csv('test_corrected.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Imputing missing values in temp and value\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Best practice to scale features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Models used for prediction\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "# Turn off setting with copy warning\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataframes for training and testing\n",
    "train = pd.read_csv('train_corrected.csv')\n",
    "test = pd.read_csv('test_corrected.csv')\n",
    "\n",
    "# Convert to datetimes\n",
    "train['Timestamp'] = pd.to_datetime(train['Timestamp'])\n",
    "test['Timestamp'] = pd.to_datetime(test['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a site id and returns a formatted training and testing set\n",
    "def process(site):\n",
    "\n",
    "    # Testing data\n",
    "    test_df = test[test['ForecastId'] == site].sort_values(['Timestamp', 'Distance'])\n",
    "    test_df = test_df.drop_duplicates(['Timestamp'], keep='first')\n",
    "\n",
    "    # Training data\n",
    "    train_df = train[train['ForecastId'] == site].sort_values(['Timestamp', 'Distance'])\n",
    "    train_df = train_df.drop_duplicates(['Timestamp'], keep='first')\n",
    "\n",
    "    # Only use past training data\n",
    "    train_df = train_df[train_df['Timestamp'] < test_df['Timestamp'].min()]\n",
    "\n",
    "    # If all training temperatures are missing, drop temperatures from both training and testing\n",
    "    if (np.all(np.isnan(train_df['Temperature']))) or (np.all(np.isnan(test_df['Temperature']))):\n",
    "        train_df = train_df.drop(labels = 'Temperature', axis=1)\n",
    "        test_df = test_df.drop(labels= 'Temperature', axis=1)\n",
    "\n",
    "    # Otherwise impute the missing temperatures\n",
    "    else:\n",
    "        temp_median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        temp_median_imputer.fit(train_df[['Temperature']])\n",
    "        train_df['Temperature'] = temp_median_imputer.transform(train_df[['Temperature']])\n",
    "        test_df['Temperature'] = temp_median_imputer.transform(test_df[['Temperature']])\n",
    "\n",
    "    # Impute the missing values\n",
    "    value_median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    value_median_imputer.fit(train_df[['Value']])\n",
    "\n",
    "    if pd.isnull(train_df['Value']).all():\n",
    "        train_df['Value'] = 0\n",
    "    else:\n",
    "        train_df['Value'] = value_median_imputer.transform(train_df[['Value']])\n",
    "\n",
    "    # Find the minimum date for converting timestamp to numeric\n",
    "    min_date = min(train_df['Timestamp'])\n",
    "\n",
    "    # Convert timestamp to numeric\n",
    "    train_df['Timestamp'] = (train_df['Timestamp'] - min_date).dt.total_seconds()\n",
    "    test_df['Timestamp']  = (test_df['Timestamp'] - min_date).dt.total_seconds()\n",
    "\n",
    "    # Interval between measurements\n",
    "    train_df['time_diff'] = train_df['Timestamp'].diff().fillna(0)\n",
    "    test_df['time_diff'] = test_df['Timestamp'].diff().fillna(0)\n",
    "\n",
    "    # Extract labels\n",
    "    train_labels = train_df['Value']\n",
    "\n",
    "    # Drop columns\n",
    "    train_df = train_df.drop(columns = ['Distance', 'SiteId', 'ForecastId', 'Value'])\n",
    "    test_df =   test_df.drop(columns = ['Distance', 'SiteId', 'ForecastId', 'Value'])\n",
    "\n",
    "\n",
    "    # Scale the features between 0 and 1 (best practice for ML)\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    train_df.loc[:, :] = scaler.fit_transform(train_df.loc[:, :])\n",
    "    test_df.loc[:, :] = scaler.transform(test_df.loc[:, :])\n",
    "\n",
    "    return train_df, train_labels, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains and predicts for all datasets, makes predictions one site at a time\n",
    "def predict():\n",
    "\n",
    "    # List of trees to use in the random forest and extra trees model\n",
    "    trees_list = list(range(50, 176, 25))\n",
    "\n",
    "    # List of site ids\n",
    "    site_list = list(set(train['ForecastId']))\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Keep track of the sites run so far\n",
    "    number = len(site_list)\n",
    "    count = 0\n",
    "\n",
    "    # Iterate through every site\n",
    "    for site in site_list:\n",
    "\n",
    "        # Features and labels\n",
    "        train_x, train_y, test_x = process(site)\n",
    "\n",
    "        # Make sure only training on past data\n",
    "        assert train_x['Timestamp'].max() < test_x['Timestamp'].min(), 'Training Data Must Come Before Testing Data'\n",
    "\n",
    "        # Initialize list of predictions for site\n",
    "        _predictions = np.array([0. for _ in range(len(test_x))])\n",
    "\n",
    "        # Iterate through the number of trees\n",
    "        for tree in trees_list:\n",
    "\n",
    "            # Create a random forest and extra trees model with the number of trees\n",
    "            model1 = RandomForestRegressor(n_estimators=tree, n_jobs=-1)\n",
    "            model2 = ExtraTreesRegressor(n_estimators=tree, n_jobs=-1)\n",
    "\n",
    "            # Fitting the model\n",
    "            model1.fit(train_x, train_y)\n",
    "            model2.fit(train_x, train_y)\n",
    "\n",
    "            # Make predictions with each model\n",
    "            _predictions += np.array(model1.predict(test_x))\n",
    "            _predictions += np.array(model2.predict(test_x))\n",
    "\n",
    "        # Average the predictions\n",
    "        _predictions = _predictions / (len(trees_list) * 2)\n",
    "\n",
    "        # Add the predictions to the list of all predictions\n",
    "        predictions.append(list(_predictions))\n",
    "\n",
    "        # Iterate the count\n",
    "        count = count + 1\n",
    "\n",
    "        # Keep track of number of buildings process so far\n",
    "        if count % 100 == 0:\n",
    "            print('Percentage Complete: {:.1f}%.'.format(100 * count / number))\n",
    "\n",
    "    # Flatten the list\n",
    "    predictions = list(chain(*predictions))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a submission file given the list of predictions and name for the submission\n",
    "def make_submission_file(predictions, name):\n",
    "\n",
    "    # Read in the submission dataframe\n",
    "    submit_df = pd.read_csv('power-laws-forecasting-energy-consumption-submission-format.csv', sep=';')\n",
    "\n",
    "    # Assign the predictions as the value\n",
    "    submit_df['Value'] = predictions\n",
    "\n",
    "    # Save the submissions to the folder of final submissions\n",
    "    submit_df.to_csv('%s.csv' % name, index = False)\n",
    "    print('Predictions saved to %s.csv' % name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Complete: 1.4%.\n",
      "Percentage Complete: 2.9%.\n",
      "Percentage Complete: 4.3%.\n",
      "Percentage Complete: 5.7%.\n",
      "Percentage Complete: 7.2%.\n",
      "Percentage Complete: 8.6%.\n",
      "Percentage Complete: 10.0%.\n",
      "Percentage Complete: 11.5%.\n",
      "Percentage Complete: 12.9%.\n",
      "Percentage Complete: 14.3%.\n",
      "Percentage Complete: 15.8%.\n",
      "Percentage Complete: 17.2%.\n",
      "Percentage Complete: 18.6%.\n",
      "Percentage Complete: 20.1%.\n",
      "Percentage Complete: 21.5%.\n",
      "Percentage Complete: 22.9%.\n",
      "Percentage Complete: 24.4%.\n",
      "Percentage Complete: 25.8%.\n",
      "Percentage Complete: 27.2%.\n",
      "Percentage Complete: 28.7%.\n",
      "Percentage Complete: 30.1%.\n",
      "Percentage Complete: 31.5%.\n",
      "Percentage Complete: 33.0%.\n",
      "Percentage Complete: 34.4%.\n",
      "Percentage Complete: 35.8%.\n",
      "Percentage Complete: 37.3%.\n",
      "Percentage Complete: 38.7%.\n",
      "Percentage Complete: 40.1%.\n",
      "Percentage Complete: 41.6%.\n",
      "Percentage Complete: 43.0%.\n",
      "Percentage Complete: 44.5%.\n",
      "Percentage Complete: 45.9%.\n",
      "Percentage Complete: 47.3%.\n",
      "Percentage Complete: 48.8%.\n",
      "Percentage Complete: 50.2%.\n",
      "Percentage Complete: 51.6%.\n",
      "Percentage Complete: 53.1%.\n",
      "Percentage Complete: 54.5%.\n",
      "Percentage Complete: 55.9%.\n",
      "Percentage Complete: 57.4%.\n",
      "Percentage Complete: 58.8%.\n",
      "Percentage Complete: 60.2%.\n",
      "Percentage Complete: 61.7%.\n",
      "Percentage Complete: 63.1%.\n",
      "Percentage Complete: 64.5%.\n",
      "Percentage Complete: 66.0%.\n",
      "Percentage Complete: 67.4%.\n",
      "Percentage Complete: 68.8%.\n",
      "Percentage Complete: 70.3%.\n",
      "Percentage Complete: 71.7%.\n",
      "Percentage Complete: 73.1%.\n",
      "Percentage Complete: 74.6%.\n",
      "Percentage Complete: 76.0%.\n",
      "Percentage Complete: 77.4%.\n",
      "Percentage Complete: 78.9%.\n",
      "Percentage Complete: 80.3%.\n",
      "Percentage Complete: 81.7%.\n",
      "Percentage Complete: 83.2%.\n",
      "Percentage Complete: 84.6%.\n",
      "Percentage Complete: 86.0%.\n",
      "Percentage Complete: 87.5%.\n",
      "Percentage Complete: 88.9%.\n",
      "Percentage Complete: 90.3%.\n",
      "Percentage Complete: 91.8%.\n",
      "Percentage Complete: 93.2%.\n",
      "Percentage Complete: 94.6%.\n",
      "Percentage Complete: 96.1%.\n",
      "Percentage Complete: 97.5%.\n",
      "Percentage Complete: 98.9%.\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to submission_filename.csv\n"
     ]
    }
   ],
   "source": [
    "# Save predictions with a sensible name\n",
    "make_submission_file(predictions, 'submission_filename')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
