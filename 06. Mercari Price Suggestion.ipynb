{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import gc\n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as Tfidf\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "warnings.filterwarnings('ignore')    # ignore warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train dataset\n",
    "\n",
    "train = pd.read_csv('data/mercari-price-suggestion-train.tsv', sep='\\t')\n",
    "train = train[train['price'] > 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset to train and validation dataset\n",
    "\n",
    "cv = KFold(n_splits=20, shuffle=True, random_state=42)\n",
    "train_ids, valid_ids = next(cv.split(train))\n",
    "train, valid = train.iloc[train_ids], train.iloc[valid_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessing functions\n",
    "\n",
    "def preprocess(df):\n",
    "    df['name'] = df['name'].fillna('') + ' ' + df['brand_name'].fillna('')\n",
    "    df['text'] = (df['item_description'].fillna('') + ' ' + df['name'] + ' ' + df['category_name'].fillna(''))\n",
    "    return df[['name', 'text', 'shipping', 'item_condition_id']]\n",
    "\n",
    "def on_field(f, *vec):\n",
    "    return make_pipeline(FunctionTransformer(itemgetter(f), validate=False), *vec)\n",
    "\n",
    "def to_records(df):\n",
    "    return df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vectorizing function\n",
    "\n",
    "vectorizer = make_union(\n",
    "    on_field('name', Tfidf(max_features=100000, token_pattern='\\w+')),\n",
    "    on_field('text', Tfidf(max_features=100000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "    on_field(['shipping', 'item_condition_id'],\n",
    "             FunctionTransformer(to_records, validate=False), DictVectorizer()),\n",
    "    n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1407577, 200002) of float32\n",
      "X_valid: (74084, 200002) of float32\n"
     ]
    }
   ],
   "source": [
    "# preprocess and vectorize both train and validation dataset\n",
    "\n",
    "X_train = vectorizer.fit_transform(preprocess(train)).astype(np.float32)\n",
    "X_valid = vectorizer.transform(preprocess(valid)).astype(np.float32)\n",
    "print(f'X_train: {X_train.shape} of {X_train.dtype}')\n",
    "print(f'X_valid: {X_valid.shape} of {X_valid.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-transform target variable\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(np.log1p(train['price'].values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete raw train dataset to save memory\n",
    "\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make binary datasets for both train and validation\n",
    "\n",
    "Xb_train, Xb_valid = [x.astype(np.bool).astype(np.float32) for x in [X_train, X_valid]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define datasets to be fit by the model: 2 for original, 2 for binary\n",
    "\n",
    "nets = 4\n",
    "models = [0] * nets\n",
    "xs_train = [Xb_train, X_train] * 2\n",
    "xs_valid = [Xb_valid, X_valid] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model 1\n",
      "==================================================\n",
      "688/688 [==============================] - 14s 21ms/step - loss: 0.3588\n",
      "344/344 [==============================] - 10s 30ms/step - loss: 0.2092\n",
      "172/172 [==============================] - 10s 61ms/step - loss: 0.1208\n",
      "Model 1 saved.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model 2\n",
      "==================================================\n",
      "688/688 [==============================] - 14s 21ms/step - loss: 0.3519\n",
      "344/344 [==============================] - 11s 32ms/step - loss: 0.2110\n",
      "172/172 [==============================] - 9s 54ms/step - loss: 0.1274\n",
      "Model 2 saved.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model 3\n",
      "==================================================\n",
      "688/688 [==============================] - 13s 19ms/step - loss: 0.3578\n",
      "344/344 [==============================] - 9s 28ms/step - loss: 0.2093\n",
      "172/172 [==============================] - 10s 60ms/step - loss: 0.1214\n",
      "Model 3 saved.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model 4\n",
      "==================================================\n",
      "688/688 [==============================] - 14s 20ms/step - loss: 0.3528\n",
      "344/344 [==============================] - 9s 27ms/step - loss: 0.2140\n",
      "172/172 [==============================] - 8s 46ms/step - loss: 0.1304: 0s - l\n",
      "Model 4 saved.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define model (Functional API), fit, and save\n",
    "\n",
    "for i in range(nets):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Model %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    train = xs_train[i]\n",
    "    \n",
    "    model_in = Input(shape=(train.shape[1],), dtype='float32', sparse=True)\n",
    "    out = Dense(192, activation='relu')(model_in)\n",
    "    out = Dense(64, activation='relu')(out)\n",
    "    out = Dense(64, activation='relu')(out)\n",
    "    out = Dense(1)(out)\n",
    "    model = Model(model_in, out)\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=3e-3))\n",
    "    \n",
    "    for j in range(3):\n",
    "        model.fit(x=train, y=y_train, batch_size=2**(11 + j), epochs=1, verbose=1)\n",
    "    \n",
    "    models[i] = model\n",
    "    print(\"Model %d saved.\\n\\n\" % (i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid RMSLE: 0.3873\n"
     ]
    }
   ],
   "source": [
    "# ensemble prediction on validation dataset and print the error\n",
    "\n",
    "y_valid = np.mean([models[i].predict(xs_valid[i])[:, 0] for i in range(nets)], axis=0)\n",
    "y_valid = np.expm1(y_scaler.inverse_transform(y_valid.reshape(-1, 1))[:, 0])\n",
    "print('Valid RMSLE: {:.4f}'.format(np.sqrt(mean_squared_log_error(valid['price'], y_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1\n",
      "Test dataset chunk size: (1000000, 200002) of float32 \n",
      "\n",
      "Processing chunk 2\n",
      "Test dataset chunk size: (1000000, 200002) of float32 \n",
      "\n",
      "Processing chunk 3\n",
      "Test dataset chunk size: (1000000, 200002) of float32 \n",
      "\n",
      "Processing chunk 4\n",
      "Test dataset chunk size: (460725, 200002) of float32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now, for the test dataset\n",
    "\n",
    "# read data in 4 chunks\n",
    "test_chunk = pd.read_csv('data/mercari-price-suggestion-test.tsv', sep='\\t', chunksize=1000000)\n",
    "\n",
    "# initialize index, prediction, and chunk number\n",
    "test_ids = []\n",
    "y_test = []\n",
    "chunk_ids = 0\n",
    "\n",
    "# iterate each chunk\n",
    "for chunk in test_chunk:\n",
    "    # free up some memory\n",
    "    gc.collect()\n",
    "    \n",
    "    # current chunk\n",
    "    chunk_ids += 1\n",
    "    print('Processing chunk', chunk_ids)\n",
    "    \n",
    "    # get index\n",
    "    test_ids.extend(chunk.test_id)\n",
    "    \n",
    "    # preprocess data\n",
    "    X_test = vectorizer.transform(preprocess(chunk)).astype(np.float32)\n",
    "    print(f'Test dataset chunk size: {X_test.shape} of {X_test.dtype} \\n')\n",
    "    Xb_test = X_test.astype(np.bool).astype(np.float32)\n",
    "    xs_test = [Xb_test, X_test] * 2\n",
    "    \n",
    "    # predict\n",
    "    y_test_chunk = np.mean([models[i].predict(xs_test[i])[:, 0] for i in range(nets)], axis=0)\n",
    "    y_test_chunk = np.expm1(y_scaler.inverse_transform(y_test_chunk.reshape(-1, 1))[:, 0])\n",
    "    y_test.extend(y_test_chunk)\n",
    "    \n",
    "# make submission\n",
    "output = pd.DataFrame({'test_id':test_ids, 'price':y_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
